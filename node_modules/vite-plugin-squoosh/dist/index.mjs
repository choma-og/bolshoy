import Debug from 'debug';
import { createLogger } from 'vite';
import path from 'path';
import fs, { readFileSync } from 'fs';
import chalk from 'chalk';
import { ImagePool } from '@squoosh/lib';
import os from 'os';

const debug = Debug.debug("vite-plugin-squoosh");
const extensions = /\.(png|jpeg|jpg|bmp|webp)$/i;

const defaultEncoderOptions = {
  mozjpeg: {
    extension: /.(jpg|jpeg)$/,
    quality: 75,
    baseline: false,
    arithmetic: false,
    progressive: true,
    optimize_coding: true,
    smoothing: 0,
    color_space: 3,
    quant_table: 3,
    trellis_multipass: false,
    trellis_opt_zero: false,
    trellis_opt_table: false,
    trellis_loops: 1,
    auto_subsample: true,
    chroma_subsample: 2,
    separate_chroma_quality: false,
    chroma_quality: 75
  },
  webp: {
    extension: /.webp$/,
    quality: 75,
    target_size: 0,
    target_PSNR: 0,
    method: 4,
    sns_strength: 50,
    filter_strength: 60,
    filter_sharpness: 0,
    filter_type: 1,
    partitions: 0,
    segments: 4,
    pass: 1,
    show_compressed: 0,
    preprocessing: 0,
    autofilter: 0,
    partition_limit: 0,
    alpha_compression: 1,
    alpha_filtering: 1,
    alpha_quality: 100,
    lossless: 0,
    exact: 0,
    image_hint: 0,
    emulate_jpeg_size: 0,
    thread_level: 0,
    low_memory: 0,
    near_lossless: 100,
    use_delta_palette: 0,
    use_sharp_yuv: 0
  },
  avif: {
    extension: /.avif$/,
    cqLevel: 33,
    cqAlphaLevel: -1,
    denoiseLevel: 0,
    tileColsLog2: 0,
    tileRowsLog2: 0,
    speed: 6,
    subsample: 1,
    chromaDeltaQ: false,
    sharpness: 0,
    tune: 0
  },
  jxl: {
    extension: /.jxl$/,
    effort: 1,
    quality: 75,
    progressive: false,
    epf: -1,
    lossyPalette: false,
    decodingSpeedTier: 0,
    photonNoiseIso: 0,
    lossyModular: false
  },
  wp2: {
    extension: /.wp2$/,
    quality: 75,
    alpha_quality: 75,
    effort: 5,
    pass: 1,
    sns: 50,
    uv_mode: 0,
    csp_type: 0,
    error_diffusion: 0,
    use_random_matrix: false
  },
  oxipng: {
    extension: /.png$/,
    level: 2
  }
};

const transformAssetPath = (assetPath, transform) => ({
  from: transform(assetPath.from),
  to: transform(assetPath.to)
});
const pushImageAssets = (filePaths, target, transformers, exclude) => filePaths.filter((path2) => isCorrectFormat(path2, extensions, exclude)).map((from) => ({
  from: transformers?.from?.call(transformers, from) ?? from,
  to: transformers?.to?.call(transformers, from) ?? from
})).forEach(({ from, to }) => {
  debug(chalk.magentaBright(from), "->", chalk.blueBright(to));
  target.push({ from, to });
});
function readFilesRecursive(root, reg) {
  let resultArr = [];
  try {
    if (fs.existsSync(root) && fs.lstatSync(root).isDirectory())
      fs.readdirSync(root).forEach((file) => resultArr = resultArr.concat(readFilesRecursive(path.join(root, "/", file))));
    else if (reg === void 0 || reg?.test(root))
      resultArr.push(root);
  } catch (error) {
    console.log(error);
  }
  return resultArr;
}
function isCorrectFormat(fileName, include, exclude) {
  if (!fileName || !include)
    return false;
  return !exclude?.test(fileName) && (include.test(fileName) || Object.values(defaultEncoderOptions).some((encoder) => encoder.extension?.test(fileName)));
}
const forEachKey = (object, callbackfn) => Object.keys(object).forEach((key, index) => callbackfn(key, object[key], index));
const getFileId = (path2) => new Uint8Array(readFileSync(path2).buffer.slice(-8)).reduce((id, byte) => id + byte, "");

const header = chalk.magentaBright("[vite-plugin-squoosh] ");
const dim = (...args) => {
  let result = "";
  args.forEach((arg) => {
    if (typeof arg === "number")
      result += arg;
    else
      result += chalk.dim(arg);
    result += " ";
  });
  return result;
};

function squooshPlugin(options = {}) {
  let outputPath;
  let publicDir;
  let config;
  let logger;
  let files = [];
  options.cacheLevel ?? (options.cacheLevel = "None");
  options.cachePath ?? (options.cachePath = "./vite-plugin-squoosh-cache.json");
  return {
    name: "vite:squoosh",
    apply: "build",
    enforce: "post",
    configResolved(resolvedConfig) {
      config = resolvedConfig;
      logger = options.silent ? createLogger("silent") : config.logger;
      publicDir = config.publicDir;
      outputPath = path.resolve(config.root, config.build.outDir);
    },
    async generateBundle(_, bundler) {
      pushImageAssets(Object.keys(bundler), files, {
        from: (file) => path.resolve(outputPath, file),
        to: (file) => path.resolve(outputPath, file)
      }, options.exclude);
    },
    async closeBundle() {
      if (publicDir)
        pushImageAssets(readFilesRecursive(publicDir), files, {
          from: (file) => path.resolve(publicDir, file),
          to: (file) => path.resolve(outputPath, path.relative(publicDir, file))
        }, options.exclude);
      if (options.includeDirs)
        for (const dir of options.includeDirs)
          if (typeof dir === "string")
            pushImageAssets(readFilesRecursive(dir), files, {}, options.exclude);
          else
            pushImageAssets(readFilesRecursive(dir.from), files, {
              from: (file) => path.resolve(config.root, file),
              to: (file) => path.resolve(dir.to, path.relative(dir.from, file))
            }, options.exclude);
      logger.info(header + dim("Processing", files.length, "assets..."), { clear: true });
      const codecs = {};
      if (options.codecs)
        forEachKey(defaultEncoderOptions, (key, value) => codecs[key] = { ...value, ...(options.codecs ?? {})[key] });
      async function processAsset(asset, encodeWith, imagePool2) {
        const start = Date.now();
        const oldSize = fs.lstatSync(asset.from).size;
        let newSize = oldSize;
        const image = imagePool2.ingestImage(asset.from);
        await image.decoded;
        await image.encode({ [encodeWith]: codecs[encodeWith] });
        const encodedWith = await Object.values(image.encodedWith)[0];
        debug("to:", encodeWith);
        newSize = encodedWith.size;
        if (newSize < oldSize) {
          fs.mkdirSync(path.dirname(asset.to), { recursive: true });
          fs.writeFileSync(asset.to, encodedWith.binary);
        }
        return { oldSize, newSize, time: Date.now() - start };
      }
      const startTime = Date.now();
      const cpus = Math.max(1, Math.min(os.cpus().length, options.coreCount ?? os.cpus().length));
      const imagePool = new ImagePool(cpus);
      debug(dim("Running on", cpus, "CPU cores."));
      debug(dim(files.length, "assets queued."));
      let cache = { options: codecs };
      if (options.cacheLevel === "Persistent" && options.cachePath) {
        if (fs.existsSync(options.cachePath))
          cache = JSON.parse(fs.readFileSync(options.cachePath, { encoding: "utf8" }));
      }
      const reuse = {};
      forEachKey(codecs, (key, codec) => reuse[key] = JSON.stringify(cache.options?.[key]) == JSON.stringify(codec));
      forEachKey(reuse, (key, codec) => {
        if (!codec && cache.assets)
          cache.assets[key] = [];
      });
      const relativePath = (p) => path.normalize(path.join(chalk.dim(config.build.outDir), chalk.blue(path.relative(outputPath, p))));
      const newAssetPaths = files.map((asset) => ({
        asset: transformAssetPath(asset, path.normalize),
        logPath: relativePath(asset.to),
        encodeWith: options.encodeTo?.find((value) => value.from.test(path.extname(asset.from)))?.to
      }));
      forEachKey(reuse, (codec) => debug(codec, "=>", reuse[codec]));
      newAssetPaths.forEach((asset) => {
        var _a, _b;
        if (!fs.existsSync(asset.asset.from))
          return;
        const ext = path.extname(asset.asset.from);
        const encodeTo = options.encodeTo?.find((value) => value.from.test(ext))?.to;
        asset.encodeWith = encodeTo ?? Object.keys(codecs).find((codec) => codecs[codec].extension?.test(ext));
        asset.size = fs.lstatSync(asset.asset.from).size;
        if (asset.encodeWith && options.cacheLevel != "None") {
          cache.assets ?? (cache.assets = {});
          (_a = cache.assets)[_b = asset.encodeWith] ?? (_a[_b] = []);
          const id = getFileId(asset.asset.from);
          const other = cache.assets[asset.encodeWith].find((other2) => other2.id === id && other2.paths.from === asset.asset.from);
          if (reuse[asset.encodeWith] && other) {
            if (fs.existsSync(other.paths.to)) {
              if (fs.lstatSync(other.paths.to).size < fs.lstatSync(asset.asset.from).size) {
                asset.asset.from = other.paths.to;
                asset.encodeWith = void 0;
              }
            }
          } else
            cache.assets[asset.encodeWith]?.push({ id, paths: asset.asset });
        }
        asset.logPath += " ";
      });
      let lastTime = 0;
      let bytesSaved = 0;
      let notHandled;
      const handles = newAssetPaths.filter((asset) => asset.encodeWith).map(async ({ asset, encodeWith, logPath }) => {
        const { oldSize, newSize, time } = await processAsset(asset, encodeWith, imagePool);
        if (newSize >= oldSize) {
          notHandled ?? (notHandled = 0);
          notHandled++;
          return;
        }
        const ratio = Math.round(100 * newSize / oldSize) - 100;
        bytesSaved += oldSize - newSize;
        logger.info(
          logPath + " " + chalk.green(`${ratio}%`) + " " + chalk.grey(`${(oldSize / 10 ** 3).toFixed(2)}kb / ${(newSize / 10 ** 3).toFixed(2)}kb`) + " " + chalk.magentaBright(`+${time - lastTime}ms`)
        );
        lastTime = time;
      });
      await Promise.all(handles);
      imagePool.close();
      newAssetPaths.filter((asset) => !asset.encodeWith).forEach(({ asset, logPath, size }) => {
        if (asset.from === asset.to)
          return;
        fs.mkdirSync(path.dirname(asset.to), { recursive: true });
        fs.copyFileSync(asset.from, asset.to);
        logger.info(
          logPath + " " + chalk.grey(`Copied from ${relativePath(asset.from)}`)
        );
        if (size)
          bytesSaved += size - fs.lstatSync(asset.to).size;
      });
      if (options.cacheLevel == "Persistent" && options.cachePath) {
        cache.options = codecs;
        fs.mkdirSync(path.dirname(options.cachePath), { recursive: true });
        fs.writeFileSync(options.cachePath, JSON.stringify(cache));
      }
      if (notHandled)
        logger.info(header + dim("Excluded", notHandled, `asset${notHandled == 1 ? "" : "s"} due to an unfavorable compression ratio.`));
      logger.info(header + chalk.cyanBright(`~${(bytesSaved / 10 ** 6).toFixed(2)}mb reduced in `) + chalk.magentaBright(`${Date.now() - startTime}ms`));
    }
  };
}

export { squooshPlugin as default };
